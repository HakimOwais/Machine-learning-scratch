{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "A Decision tree is a supervised machine learning algorithm used for classification and regression tasks. It models decisions as a tree-like structure where each node represents a decision based on each feature values.\n",
    "\n",
    "It works by:\n",
    "1. Selecting the best feature to split the dataset using a metric like Gini Index or Entropy (Information Gain).\n",
    "2. recursively splittong data into subsets until it reaches a stopping condition (e.g. pure classes or max depth).\n",
    "3. Assigning labels (classification) or computing averages (regression) at the leaf node.\n",
    "\n",
    "### Assumptions\n",
    "1. Data is structured, works best when features have clear relationship with target variable.\n",
    "2. Assumes that data can be divided into smaller groups where patterns emerge.\n",
    "3. The relationships between features and labels are hierarchical.\n",
    "\n",
    "### Limitation\n",
    "1. Overfitting. (As trees grow deep) (Use pruning to reduce overfitting)\n",
    "2. Sensitive to small variations in Data\n",
    "3. Biased with Imbalanced Data\n",
    "4. Cannot Model complex Relationships well (Use Random Forest or Gradient Boosting)\n",
    "\n",
    "### When to use?\n",
    "1. Interpretable models – When human readability is important (e.g., medical diagnosis).\n",
    "2. Non-linear relationships – When simple rules separate classes well.\n",
    "3. Low-latency predictions – After training, predictions are fast.\n",
    "4. Feature importance analysis – Can show which features matter most.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, features=None, threshold=None,\n",
    "                 left=None, right=None, * , value=None):\n",
    "        self.features = features\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100,\n",
    "                 n_features=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.root = self.grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        # cheking for the stopping criteria\n",
    "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        feat_idxs = np.random.choice(n_feats,\n",
    "                                     self.n_features,\n",
    "                                     replace=False)\n",
    "        # find the best fit\n",
    "        best_feature, best_threshold = self._best_split(X, y, feat_idxs)\n",
    "\n",
    "        # creating the child nodes\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "\n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "\n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idxs, split_threshold = None, None\n",
    "\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "\n",
    "            for thr in thresholds:\n",
    "                # calculate the information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "\n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # creating a children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # calculate the weighted average entropy of children \n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r\n",
    "\n",
    "        # calculate the information gain\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain   \n",
    "\n",
    "    def _split(self):\n",
    "        pass\n",
    "\n",
    "    def _entropy(self):\n",
    "        pass\n",
    "\n",
    "    def _most_common_label(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def _traverse_tree(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
