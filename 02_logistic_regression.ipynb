{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is a statistical method used for binary classification problems, where the goal is to predict the probability of an outcome that can take one of two possible values (yes/no or 0/1).\n",
    "\n",
    "### Assumptions\n",
    "1. Binary Outcome.\n",
    "2. Independence of Observations (No repeated measures or clustering)\n",
    "3. Linearity of Independent variales and Log Odds (logit). (Can be checked using the Box-Tidwell test or by plotting the log odds against the predictors).\n",
    "4. No Multicollinearity (Can be checked using Variance Inflation Factor)\n",
    "5. Large Sample size\n",
    "6. No Outliers\n",
    "\n",
    "### Limitations\n",
    "1. Linear decision boundary\n",
    "2. Sensitive to irrelevant features\n",
    "3. Overfitting with Too many Predictors\n",
    "4. Assumptions of Independence.\n",
    "5. Limited to Binary or Ordinal Outcomes.\n",
    "6. Interpretability with interaction terms (polynomial terms can make the model harder to interpret)\n",
    "7. Not Suitable for Non-linear Relationships\n",
    "\n",
    "### When to Use Logistic Regression\n",
    "\n",
    "1. When the outcome is binary.\n",
    "2. When interpretability of the model is important.\n",
    "3. When the relationship between predictors and the log odds is approximately linear.\n",
    "4. When the dataset is not too large or complex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo Code \n",
    "# P(Y=1) = 1 / (1 + e^(-z)) , which is a sigmoid function\n",
    "#  where z = a0 + a1x1 + ... + anxn\n",
    "# initialize weights\n",
    "# define sigmoid function\n",
    "# compute cost function\n",
    "# Gradient descent for para meter updates\n",
    "# training loop\n",
    "# prediction function\n",
    "# model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape # rows represent samples, col represent features\n",
    "        self.coef_ = np.zeros(n_features)\n",
    "        self.intercept_ = 0\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            linear_pred = np.dot(X, self.coef_) + self.intercept_ # linear eqn y = xA + b\n",
    "            predictions = sigmoid(linear_pred)\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.coef_ = self.coef_ - self.learning_rate * dw\n",
    "            self.intercept_ = self.intercept_ - self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "         linear_pred = np.dot(X, self.coef_) + self.intercept_ \n",
    "         y_pred = sigmoid(linear_pred)\n",
    "         class_pred = [0 if y<=0.5 else 1 for y in y_pred]\n",
    "         return class_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/qngwbvxs1qz7qvqkn32lww080000gn/T/ipykernel_4977/2606460733.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = CustomLogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)\n",
    "\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
