{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (K-NN) Algorithm\n",
    "K-Nearest Neighbors (K-NN) is a non-parametric, lazy learning algorithm used for classification and regression. It classifies a data point based on how its neighbors are classified.\n",
    "\n",
    "### It works by:\n",
    "\n",
    "1. Storing the entire dataset.\n",
    "2. Calculating the distance between the new data point and all existing data  points (e.g., Euclidean distance).\n",
    "3. Selecting the K nearest points.\n",
    "4. Assigning the majority class (for classification) or averaging the values (for regression).\n",
    "\n",
    "### Assumptions of K-NN\n",
    "1. Similarity-based learning: Assumes that similar data points exist close to each other.\n",
    "2. Locally relevant features: Assumes that nearby points contribute more to prediction than distant ones.\n",
    "3. Balanced data: Works best when the dataset is balanced across classes.\n",
    "\n",
    "### Limitations of K-NN\n",
    "1. Computationally expensive: As it stores all training data, it is slow when dealing with large datasets.\n",
    "2. Memory-intensive: Needs to keep all data points in memory.\n",
    "3. Curse of dimensionality: High-dimensional data makes distance metrics less meaningful.\n",
    "4. Sensitive to noise: Outliers can affect classification.\n",
    "5. Choosing K is tricky: A small K may lead to noise sensitivity, while a large K may oversmooth the decision boundary.\n",
    "\n",
    "### When to use KNN\n",
    "1. Small to Medium-Sized Datasets\n",
    "2. Low-Dimensional Data\n",
    "3. Well Separated Classes\n",
    "4. Non-Parametric problems (If we don't know the data distribution). KNN is a good choice because it doesn't assume any underlying mathematical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K-NN Algorithm Pseudo Code\n",
    "\n",
    "# 1. Load the dataset (training samples with labels).\n",
    "# 2. Choose the value of K (number of nearest neighbors).\n",
    "# 3. For each test sample:\n",
    "#     a. Compute the distance from the test sample to all training samples.\n",
    "#     b. Sort the distances in ascending order.\n",
    "#     c. Pick the K closest neighbors.\n",
    "#     d. For classification:\n",
    "#         - Count the occurrences of each class among the K neighbors.\n",
    "#         - Assign the most frequent class to the test sample.\n",
    "#     e. For regression:\n",
    "#         - Compute the average of the K nearest values.\n",
    "# 4. Return the predicted label or value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
